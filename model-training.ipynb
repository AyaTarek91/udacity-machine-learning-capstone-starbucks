{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model\n",
    "\n",
    "In this notebook we will train our three models `Logistic Regression, Decision Tree and Random Forest`, and compare the accuracy to decide which model is the best for our data to classify the customer response.\n",
    "\n",
    "\n",
    "#### To train my models, I will be using:\n",
    "1. Cross validation method to get the best training data to avoid over and under fitting.\n",
    "2. Grid search for parameter selection and comparing accuricies of different hyper-parameters and to select the best parameter for each model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features and target data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'uploaded_data'\n",
    "train_data = pd.read_csv(os.path.join(directory, 'train.csv'), header=None)\n",
    "X_train = train_data.iloc[:, :-1].values #all until last column\n",
    "Y_train = train_data.iloc[:, -1].values #only last column\n",
    "\n",
    "test_data = pd.read_csv(os.path.join(directory, 'test.csv'), header=None)\n",
    "X_test = test_data.iloc[:, :-1].values #all until last column\n",
    "Y_test = test_data.iloc[:, -1].values #only last column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will split the data into 4 folds, cross_val_score will divide them into 3 training sets and 1 testing set, so the test is 25% of the training data set, which is 20% of the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.743866  , 0.75181094, 0.75679102, 0.75552336])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.20%\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation scores on 4 folds \n",
    "lr = LogisticRegression()\n",
    "scores_arr = cross_val_score(lr,X_train,Y_train,cv=4,n_jobs=-1)\n",
    "display(scores_arr)\n",
    "print(\"Accuracy: %.2f%%\" % (scores_arr.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR best parameter: {'C': 1, 'max_iter': 50}\n",
      "LR best score: 75.20%\n",
      "LR best estimator: LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=50, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find the best parameters to fit to maximize the cross validation scores\n",
    "gridsearch_param = {\n",
    "    'C': [0.1,1,10,100],\n",
    "    'max_iter' : [50,100,1000,10000],\n",
    "}\n",
    "\n",
    "gsv_lr = GridSearchCV(estimator=lr,param_grid=gridsearch_param,\\\n",
    "                   cv=4, n_jobs=-1,scoring ='accuracy')\n",
    "\n",
    "lr_model = gsv_lr.fit(X_train,Y_train)\n",
    "\n",
    "best_lr_parameters = gsv_lr.best_params_\n",
    "best_lr_score = gsv_lr.best_score_\n",
    "best_lr_estimator = gsv_lr.best_estimator_\n",
    "\n",
    "print('LR best parameter:',best_lr_parameters)\n",
    "print(\"LR best score: %.2f%%\" % (best_lr_score*100.0))\n",
    "print('LR best estimator:',best_lr_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75002263, 0.75316914, 0.76014125, 0.75715321])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Accuracy: 75.51%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc= DecisionTreeClassifier()\n",
    "scores_arr = cross_val_score(dtc,X_train,Y_train,cv=4,n_jobs=-1)\n",
    "display(scores_arr)\n",
    "print(\"Min Accuracy: %.2f%%\" % (scores_arr.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT best parameter: {'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 3, 'splitter': 'best'}\n",
      "DT best score: 77.27%\n",
      "DT best estimator: DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=3,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find the best parameters to fit to maximize the cross validation scores\n",
    "gridsearch_param = {\n",
    "    'max_depth': [4,6,8,9,10,20],\n",
    "    'splitter' : ['best', 'random'],\n",
    "    'min_samples_split' : np.arange(3, 15),\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "gsv_dt = GridSearchCV(estimator=dtc,param_grid=gridsearch_param,\\\n",
    "                   cv=4, n_jobs=-1)\n",
    "\n",
    "dt_model = gsv_dt.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "best_dt_parameters = gsv_dt.best_params_\n",
    "best_dt_score = gsv_dt.best_score_\n",
    "best_dt_estimator = gsv_dt.best_estimator_\n",
    "\n",
    "print('DT best parameter:',best_dt_parameters)\n",
    "print(\"DT best score: %.2f%%\" % (best_dt_score*100.0))\n",
    "print('DT best estimator:',best_dt_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75382526, 0.7559761 , 0.76095618, 0.76331039])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Accuracy: 75.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf= RandomForestClassifier()\n",
    "scores_arr = cross_val_score(rf,X_train,Y_train,cv=4,n_jobs=-1)\n",
    "display(scores_arr)\n",
    "print(\"Min Accuracy: %.2f%%\" % (scores_arr.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best parameter: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 9, 'n_estimators': 100}\n",
      "RF best score: 77.38%\n",
      "RF best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=9,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find the best parameters to fit to maximize the cross validation scores\n",
    "gridsearch_param = {\n",
    "    'max_depth': [4,6,8,10,12],\n",
    "    'n_estimators' : [20,50,100,200],\n",
    "    'min_samples_split' : np.arange(3, 15),\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "gsv_rf = GridSearchCV(estimator=rf,param_grid=gridsearch_param,\\\n",
    "                   cv=4, n_jobs=-1)\n",
    "\n",
    "rf_model = gsv_rf.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "best_rf_parameters = gsv_rf.best_params_\n",
    "best_rf_score = gsv_rf.best_score_\n",
    "best_rf_estimator = gsv_rf.best_estimator_\n",
    "\n",
    "print('RF best parameter:',best_rf_parameters)\n",
    "print(\"RF best score: %.2f%%\" % (best_rf_score*100.0))\n",
    "print('RF best estimator:',best_rf_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "My benchmark for evaluating the models is an accuracy of at least 75% and a low percentage of FN as we don't need to predict that a customer may not respond to an offer while he will actually do respond."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models saving and loading using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#save to file\n",
    "with open('Logisticregression.pkl', 'wb') as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "    \n",
    "with open('DecisionTree.pkl', 'wb') as file:\n",
    "    pickle.dump(dt_model, file)\n",
    "    \n",
    "with open('RandomForest.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from file\n",
    "with open('Logisticregression.pkl', 'rb') as file:\n",
    "    lr_trained_model = pickle.load(file)\n",
    "    \n",
    "with open('DecisionTree.pkl', 'rb') as file:\n",
    "    dt_trained_model = pickle.load(file)\n",
    "    \n",
    "with open('RandomForest.pkl', 'rb') as file:\n",
    "    rf_trained_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  After loading the models, it's time to test each model and see check testing scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Test score: 75.57 %\n",
      "DT Test score: 77.19 %\n",
      "RF Test score: 77.34 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the  score and predict the targets for all three trianed models\n",
    "lr_score = lr_trained_model.score(X_test, Y_test)\n",
    "print(\"LR Test score: {0:.2f} %\".format(100 * lr_score))\n",
    "lr_Y_predict = lr_trained_model.predict(X_test)\n",
    "\n",
    "dt_score = dt_trained_model.score(X_test, Y_test)\n",
    "print(\"DT Test score: {0:.2f} %\".format(100 * dt_score))\n",
    "dt_Y_predict = dt_trained_model.predict(X_test)\n",
    "\n",
    "rf_score = rf_trained_model.score(X_test, Y_test)\n",
    "print(\"RF Test score: {0:.2f} %\".format(100 * rf_score))\n",
    "rf_Y_predict = rf_trained_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "#### We will use sklearn.metrics to help evaluating the three models and compare the results using:\n",
    "* Accuracy\n",
    "* Confusion matrix, as we want to select the model with highest TP and lowest FN count\n",
    "* Recall\n",
    "* Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score\n",
    "\n",
    "# Calculate the metrics\n",
    "def model_eval(y_test,y_predicted):\n",
    "    accuracy = metrics.accuracy_score(y_test, y_predicted)\n",
    "    conf_matrix = metrics.confusion_matrix(y_test, y_predicted)\n",
    "    precision = metrics.precision_score(y_test, y_predicted)\n",
    "    recall = metrics.recall_score(y_test, y_predicted)\n",
    "    return accuracy,conf_matrix,precision,recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_acc,lr_conf,lr_prec,lr_rec = model_eval(Y_test,lr_Y_predict)\n",
    "dt_acc,dt_conf,dt_prec,dt_rec = model_eval(Y_test,dt_Y_predict)\n",
    "rf_acc,rf_conf,rf_prec,rf_rec = model_eval(Y_test,rf_Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy %</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>75.57%</td>\n",
       "      <td>0.7166</td>\n",
       "      <td>0.8534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>77.19%</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>0.8233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>77.34%</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.8611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Accuracy %  Precision  Recall\n",
       "Logistic Regression     75.57%     0.7166  0.8534\n",
       "Decision Tree           77.19%     0.7495  0.8233\n",
       "Random Forest           77.34%     0.7352  0.8611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compare the results in one dataframe\n",
    "model_comp_df = pd.DataFrame(\n",
    "    [[f'{lr_acc*100:.2f}%', lr_prec, lr_rec], \n",
    "    [f'{dt_acc*100:.2f}%', dt_prec, dt_rec],\n",
    "    [f'{rf_acc*100:.2f}%', rf_prec, rf_rec]],\n",
    "    columns=['Accuracy %', 'Precision', 'Recall'],\n",
    "    index=['Logistic Regression','Decision Tree','Random Forest'])\n",
    "\n",
    "pd.set_option('display.precision', 4)\n",
    "display(model_comp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix construction\n",
    "\n",
    "def conf_matrix(con_matrix, ax):\n",
    "    ax.matshow(con_matrix, cmap='BuGn')\n",
    "    ax.set_xlabel('Confusion Matrix')\n",
    "    ax.text(0, 0, f'TP\\n{con_matrix[1,1]}',\n",
    "            ha=\"center\", va=\"center\", color=\"w\")\n",
    "    ax.text(0, 1, f'FP\\n{con_matrix[0,1]}',\n",
    "            ha=\"center\", va=\"center\", color=\"k\")\n",
    "    ax.text(1, 0, f'FN\\n{con_matrix[1,0]}',\n",
    "            ha=\"center\", va=\"center\", color=\"k\")\n",
    "    ax.text(1, 1,f'TN\\n{con_matrix[0,0] }',\n",
    "            ha=\"center\", va=\"center\", color=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3)\n",
    "\n",
    "conf_matrix(lr_conf, axs[0]) \n",
    "axs[0].set_title('Logistic regression\\n')\n",
    "\n",
    "conf_matrix(dt_conf, axs[1])\n",
    "axs[1].set_title('Decision Tree\\n')\n",
    "\n",
    "conf_matrix(rf_conf, axs[2])\n",
    "axs[2].set_title('Random Forest\\n')\n",
    "\n",
    "fig.set_size_inches(11,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The confusion matrix shows that the random forest has the highest accuracy 77.3% and TP count 4800 and the lowest FN count 774."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model refinement \n",
    "\n",
    "Since the highest accuracy belongs to the Random forest model, we will take this model and apply some refinement on by changing the hyperparameters and check if we can get a higher accuracy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75255772, 0.75325969, 0.76005071, 0.76294821])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Accuracy: 75.72%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_refined= RandomForestClassifier()\n",
    "scores_arr = cross_val_score(rf_refined,X_train,Y_train,cv=4,n_jobs=-1)\n",
    "display(scores_arr)\n",
    "print(\"Min Accuracy: %.2f%%\" % (scores_arr.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best parameter: {'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 14, 'n_estimators': 250}\n",
      "RF best score: 77.10%\n",
      "RF best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=14, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=14,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find the best parameters to fit to maximize the cross validation scores\n",
    "gridsearch_param = {\n",
    "    'max_depth': [14,16,18,20],\n",
    "    'n_estimators' : [250,300,350,400],\n",
    "    'min_samples_split' : np.arange(14,15,16),\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "gsv_rf_refined = GridSearchCV(estimator=rf_refined,param_grid=gridsearch_param,\\\n",
    "                   cv=4, n_jobs=-1)\n",
    "\n",
    "rf_model_refined = gsv_rf_refined.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "best_rf_refined_parameters = gsv_rf_refined.best_params_\n",
    "best_rf_refined_score = gsv_rf_refined.best_score_\n",
    "best_rf_refined_estimator = gsv_rf_refined.best_estimator_\n",
    "\n",
    "print('RF best parameter:',best_rf_refined_parameters)\n",
    "print(\"RF best score: %.2f%%\" % (best_rf_refined_score*100.0))\n",
    "print('RF best estimator:',best_rf_refined_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The trained first Random Forest model had better accuracy than the refined one, and since the Gridsearch technique applys all iterations given, we can give it another try by reducing the values of the hyperparameters instead of increasing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75237664, 0.75706266, 0.76439696, 0.76376313])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Accuracy: 75.94%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_refined1= RandomForestClassifier()\n",
    "scores_arr = cross_val_score(rf_refined1,X_train,Y_train,cv=4,n_jobs=-1)\n",
    "display(scores_arr)\n",
    "print(\"Min Accuracy: %.2f%%\" % (scores_arr.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF best parameter: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 20}\n",
      "RF best score: 77.15%\n",
      "RF best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=4,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Grid search to find the best parameters to fit to maximize the cross validation scores\n",
    "gridsearch_param = {\n",
    "    'max_depth': [8,9],\n",
    "    'n_estimators' : [10,20,30],\n",
    "    'min_samples_split' : np.arange(4,5,6),\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "gsv_rf_refined1 = GridSearchCV(estimator=rf_refined1,param_grid=gridsearch_param,\\\n",
    "                   cv=4, n_jobs=-1)\n",
    "\n",
    "rf_model_refined1 = gsv_rf_refined1.fit(X_train,Y_train)\n",
    "\n",
    "\n",
    "best_rf_refined_param = gsv_rf_refined1.best_params_\n",
    "best_rf_refined_sc = gsv_rf_refined1.best_score_\n",
    "best_rf_refined_est = gsv_rf_refined1.best_estimator_\n",
    "\n",
    "print('RF best parameter:',best_rf_refined_param)\n",
    "print(\"RF best score: %.2f%%\" % (best_rf_refined_sc*100.0))\n",
    "print('RF best estimator:',best_rf_refined_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Still the 1st trained Random Forest model has the highest accuracy, so no more refinement needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project I addressed the problem of not all customers respond to the offers sent by merchants the same way.Some customers donâ€™t view the offers because they are not interested, others may be not interested in that particular offer they received. \n",
    "My model will predict and identify whether the customer will respond and complete these offers or not.\n",
    "\n",
    "First, I downloaded the datasets and explored each of them and started to eliminate some of the non-related features and to normalize other features that has non-numeric values in order to be able to feed the models with more meaningful data.\n",
    "After that I merged the three datasets into one grouped by customers that simply illustrate the relation between the customer demographic data, his/her previous transactions and reponses to offers and the offers discriptive data.\n",
    "\n",
    "I chose to train 3 models for this binary classification problem: Logisctic Regression, Decision tree and Random Forest.\n",
    "\n",
    "I chose to use the Cross Validation for training and splitting my data to choose the best folds to train, which helped in improving the training/learning accuracy of my models.\n",
    "Then, I decided to work with Grid search to find the best model hyperparameters which also helped in improving the accuracy of my models, it saved me a lot of time and gave me a clear view of the best hyperparameters to use.\n",
    "\n",
    "The Random Forest model performed the best with a testing accuracy of 77.34% and a very small FN percentage of 16%.\n",
    "\n",
    "As an improvement to the model, I can only think of other features that may help in training the model, for example: we can create features that describe the frequency of the customer visits to Starbucks in a month and another feature to describe the payment method (cash/CC).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
